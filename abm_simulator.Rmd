---
title: "Agent-based model simulator"
author: "Necantis"
date: "2018-08-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Part 1: Preliminary tests

Testing a [tutorial on ABM](https://marcosmolla.wordpress.com/2015/07/16/an-introduction-to-agent-based-modelling-in-r/)

```{r simulation1}
#Function to reset the results
setup <- function() {
  return(data.frame(
  id = 1:2,
  strategy = NA,
  num_wins = 0
  ))
}

#Function to set each agent's Strategy
chooseStrategy <- function(ind){
  strats <- sample(x = 1:3, size = nrow(ind)) # chose randomly a strategy among (1:Paper, 2:Scissors, 3:Rock) for each row in the matrix
  ind$strategy <- strats #Add a columns called strategy
  return(ind)
}

# Function to play strategy
playStrategy <- function(ind) {
  if (ind$strategy[1] == ind$strategy[2]) { # Do nothing if they have the same strategy
  } else{
  #in the case that one chose Rock and the other paper:
  if (any(ind$strategy == 3) && any(ind$strategy == 1)) {
  tmp <- ind[ind$strategy == 1, "id"]
  ind[tmp, "num_wins"] <- ind[tmp, "num_wins"] + 1
  } else{
  #for the two other cases, the better weapon wins:
  tmp <- which(ind[, "strategy"] == max(ind[, "strategy"]))
  ind[tmp, "num_wins"] <- ind[tmp, "num_wins"] + 1
  }
  }
  return(ind)
}

#Running the simulation
rounds <- 1000 # Set 1k rounds
indDF <- setup() # Initiate vector for results
dat <- matrix(NA, rounds, 2) #creates a matrix of NA, with a number of ronds equal to rounds and 2 columns (strategy and num_wins)
for (i in 1:rounds) {
  indDF <- chooseStrategy(indDF) #Give a strategy to each agent
  indDF <- playStrategy(indDF) # Agent play according to the strategy
  dat[i,] <- indDF$num_wins # Check outcomes
  i <- i + 1 # This step makes it jump by 2 each time
}

#Visualize results
plot(
  dat[, 1],
  type = 'l',
  col = '#EA2E49',
  lwd = 3,
  xlab = 'time',
  ylab = 'number of rounds won'
)
lines(dat[, 2], col = '#77C4D3', lwd = 3)

```


```{r}
chooseStrategy2 <- function(ind){
strats <- sample(x=1:3, size=1) # 1:Paper, 2:Scissors, 3:Rock
ind$strategy[2] <- strats
return(ind)
}

rounds <- 1000
repetitions <- 100
dat <- matrix(NA, rounds, 2)
res2 <- c()
for(j in 1:repetitions){
indDF <- setup()
indDF[1,"strategy"] <- sample(1:3,1)
for(i in 1:rounds){
indDF <- chooseStrategy2(indDF)
indDF <- playStrategy(indDF)
dat[i,] <- indDF$num_wins
i <- i+1
}
res2 <- c(res2, which(indDF[,"num_wins"]==max(indDF[,"num_wins"])))
j <- j+1
}
 
plot(dat[,1], type='l', col='blue', lwd=3, xlab='time', ylab='number of rounds won')
lines(dat[,2], col='red', lwd=3)
 
# for comparison let's calculate the winning vector for both players switch strategies:
 
res1 <- c()
for(j in 1:repetitions){
indDF <- setup()
for(i in 1:rounds){
indDF <- chooseStrategy(indDF)
indDF <- playStrategy(indDF)
dat[i,] <- indDF$num_wins
i <- i+1
}
res1 <- c(res1, which(indDF[,"num_wins"]==max(indDF[,"num_wins"])))
j <- j+1
}
 
# and the winner is:
t.test(res1,res2)
 
##
## Welch Two Sample t-test
##
## data: res1 and res2
## t = 0.5579, df = 202, p-value = 0.5775
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
## -0.09938468 0.17781605
## sample estimates:
## mean of x mean of y
## 1.529412 1.490196


```


## Theoretical model, version 01
In this initial model, we have 2 phases  
# Phase 01: Idea generation 
We assign a random number to each agent
```{r phase01.1}
target <- 1e9 # we set the target at 1'000'000'000
totAgents <- 1e3
clusters <- 10

set.seed(1) #Setting a seed to allow comparable results
ideas <- runif(totAgents, min=0, max=target) # Generating random numbers in a uniform distribution
```
We cluster the results
```{r phase01.2}
ideaClusters <- 1+as.integer(ideas/(target/clusters)) #Extracting the cluster by dividing each number to the number of clusters
agentsId <- 1:totAgents # Adding a UID
agentsReward_01 <- rep(0,totAgents) # A variable associated to phase 01
agentsReward_02 <- rep(0,totAgents) # A variable associated to phase 02
agents <- data.frame(agentsId, ideas, ideaClusters,agentsReward_01,agentsReward_02) #Creating a dataframe with ID, value and cluster

# hist(agents$ideas)
# hist(agents$ideaClusters)
```
We assign prizes
```{r phase01.3}
idClusters <- seq(1:clusters)
idWinners <- rep(NA,clusters)
valueWinners <- rep(NA,clusters)
listWinners <- data.frame(idClusters,idWinners, valueWinners) #Creating a dataframe with Cluster ID, Winner ID and value

for(i in 1:totAgents){
  j <- agents[i,3] # Check the cluster of the agent
  if(is.na(listWinners[j,2])){ # If the cluster of the agent does not have a winner (it's value is NA) ...
    listWinners[j,2] <-agents[i,1] # ... use the agent's ID
    listWinners[j,3] <-agents[i,2] # ... use the agent's value 
    agents[i,4] <- 1 # rewarding the selected agent
  }
}

listWinners
```

#Phase 02: Idea pooling 
We use [lpSOlve](https://www.kdnuggets.com/2018/05/optimization-using-r.html) to define the objective function
```{r phase02.1}
library(lpSolve)
objective.in <- listWinners[,3] # Pooling the retained ideas by looking for the best combination
```

We define the constraints of the function
```{r phase02.2}
mat <- matrix(listWinners[,3], nrow=1, byrow=TRUE) # The sum of the pooled ideas ...
dir <- "<=" # ... should be below ...
rhs <- target # ... the target
```

We solve the Linear programming function and we reward the owners of the pooled ideas
```{r phase02.3}
optimum <-lp(direction="max",  objective.in, mat, dir, rhs, all.bin = TRUE) # Which is the best combination of pooled ideas?
optimum$solution # The selected ideas

for(i in 1:clusters){
  if(optimum$solution[i] >0){ # if an idea is pooled ...
    j <- listWinners[i,2] # ... select the owner of the pooled idea
    agents[j,5] <- 1 # ... and reward the agent another time
  }
}

remainder <- target - optimum$objval #Comparing the initial target with the sum of the pooled ideas
```

** Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
